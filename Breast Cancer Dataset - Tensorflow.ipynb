{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Dataset - Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data from:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives:\n",
    "\n",
    "Based on the breast cancer dataset, the aim of this study is to predict if the class \n",
    "of the tumor is malignant or benign using tensorflow. In this project no exploratory data analysis will be performed, but if you wish to see some you can access our other project \"Breast Cancer Diagnostic - Support Vector Machine.ipynb\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries and the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dataset is presented in a dictionary form\n",
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "# Let's read the description of the dataset available to us.\n",
    "print(cancer['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Up the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38           122.8     1001.0          0.11840   \n",
       "1        20.57         17.77           132.9     1326.0          0.08474   \n",
       "2        19.69         21.25           130.0     1203.0          0.10960   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33            184.6   \n",
       "1                 0.05667  ...         24.99          23.41            158.8   \n",
       "2                 0.05999  ...         23.57          25.53            152.5   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe for the features\n",
    "df_feat = pd.DataFrame(cancer['data'],columns=cancer['feature_names'])\n",
    "df_feat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cancer\n",
       "0       0\n",
       "1       0\n",
       "2       0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe for the target\n",
    "df_target = pd.DataFrame(cancer['target'],columns=['Cancer'])\n",
    "df_target.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>Cancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  Cancer  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat the dataframes\n",
    "df = pd.concat([df_feat, df_target], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  Cancer                   569 non-null    int32  \n",
      "dtypes: float64(30), int32(1)\n",
      "memory usage: 135.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Dataset\n",
    "\n",
    "Let's start by splitting our data into a training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import the split library\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('Cancer', axis=1), df['Cancer'], test_size=0.30)\n",
    "N, D = X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import the libraries first\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=30,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=15,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=1, input_shape=(D,),activation='sigmoid'))\n",
    "\n",
    "# For a binary classification problem\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainning the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library for an early stop \n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an early stop\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.8636 - accuracy: 0.6055 - val_loss: 0.4922 - val_accuracy: 0.8480\n",
      "Epoch 2/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.6508 - val_loss: 0.3688 - val_accuracy: 0.9415\n",
      "Epoch 3/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7437 - val_loss: 0.2970 - val_accuracy: 0.9532\n",
      "Epoch 4/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7889 - val_loss: 0.2443 - val_accuracy: 0.9649\n",
      "Epoch 5/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8166 - val_loss: 0.2062 - val_accuracy: 0.9649\n",
      "Epoch 6/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8191 - val_loss: 0.1794 - val_accuracy: 0.9708\n",
      "Epoch 7/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8317 - val_loss: 0.1590 - val_accuracy: 0.9708\n",
      "Epoch 8/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8492 - val_loss: 0.1413 - val_accuracy: 0.9708\n",
      "Epoch 9/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8869 - val_loss: 0.1250 - val_accuracy: 0.9708\n",
      "Epoch 10/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8719 - val_loss: 0.1129 - val_accuracy: 0.9708\n",
      "Epoch 11/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2825 - accuracy: 0.8593 - val_loss: 0.1020 - val_accuracy: 0.9708\n",
      "Epoch 12/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2704 - accuracy: 0.8719 - val_loss: 0.0939 - val_accuracy: 0.9708\n",
      "Epoch 13/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.9020 - val_loss: 0.0865 - val_accuracy: 0.9766\n",
      "Epoch 14/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.9296 - val_loss: 0.0795 - val_accuracy: 0.9766\n",
      "Epoch 15/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2541 - accuracy: 0.8945 - val_loss: 0.0740 - val_accuracy: 0.9766\n",
      "Epoch 16/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2204 - accuracy: 0.9095 - val_loss: 0.0687 - val_accuracy: 0.9825\n",
      "Epoch 17/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.8995 - val_loss: 0.0635 - val_accuracy: 0.9883\n",
      "Epoch 18/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2012 - accuracy: 0.9271 - val_loss: 0.0599 - val_accuracy: 0.9883\n",
      "Epoch 19/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.9196 - val_loss: 0.0565 - val_accuracy: 0.9883\n",
      "Epoch 20/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2003 - accuracy: 0.9347 - val_loss: 0.0537 - val_accuracy: 0.9942\n",
      "Epoch 21/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2068 - accuracy: 0.9221 - val_loss: 0.0511 - val_accuracy: 0.9942\n",
      "Epoch 22/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.9447 - val_loss: 0.0494 - val_accuracy: 0.9825\n",
      "Epoch 23/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1578 - accuracy: 0.9472 - val_loss: 0.0472 - val_accuracy: 0.9825\n",
      "Epoch 24/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1678 - accuracy: 0.9548 - val_loss: 0.0450 - val_accuracy: 0.9825\n",
      "Epoch 25/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1851 - accuracy: 0.9548 - val_loss: 0.0431 - val_accuracy: 0.9825\n",
      "Epoch 26/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1744 - accuracy: 0.9497 - val_loss: 0.0423 - val_accuracy: 0.9825\n",
      "Epoch 27/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1621 - accuracy: 0.9422 - val_loss: 0.0412 - val_accuracy: 0.9825\n",
      "Epoch 28/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.9447 - val_loss: 0.0400 - val_accuracy: 0.9825\n",
      "Epoch 29/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1541 - accuracy: 0.9372 - val_loss: 0.0394 - val_accuracy: 0.9825\n",
      "Epoch 30/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1283 - accuracy: 0.9573 - val_loss: 0.0384 - val_accuracy: 0.9825\n",
      "Epoch 31/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1400 - accuracy: 0.9447 - val_loss: 0.0370 - val_accuracy: 0.9825\n",
      "Epoch 32/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1253 - accuracy: 0.9623 - val_loss: 0.0359 - val_accuracy: 0.9825\n",
      "Epoch 33/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1496 - accuracy: 0.9347 - val_loss: 0.0349 - val_accuracy: 0.9825\n",
      "Epoch 34/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1477 - accuracy: 0.9523 - val_loss: 0.0346 - val_accuracy: 0.9825\n",
      "Epoch 35/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1217 - accuracy: 0.9598 - val_loss: 0.0338 - val_accuracy: 0.9825\n",
      "Epoch 36/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1584 - accuracy: 0.9523 - val_loss: 0.0340 - val_accuracy: 0.9883\n",
      "Epoch 37/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1238 - accuracy: 0.9573 - val_loss: 0.0338 - val_accuracy: 0.9883\n",
      "Epoch 38/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1412 - accuracy: 0.9523 - val_loss: 0.0334 - val_accuracy: 0.9883\n",
      "Epoch 39/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1378 - accuracy: 0.9548 - val_loss: 0.0331 - val_accuracy: 0.9883\n",
      "Epoch 40/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1402 - accuracy: 0.9548 - val_loss: 0.0331 - val_accuracy: 0.9883\n",
      "Epoch 41/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1279 - accuracy: 0.9598 - val_loss: 0.0343 - val_accuracy: 0.9825\n",
      "Epoch 42/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1117 - accuracy: 0.9623 - val_loss: 0.0341 - val_accuracy: 0.9825\n",
      "Epoch 43/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0991 - accuracy: 0.9648 - val_loss: 0.0345 - val_accuracy: 0.9825\n",
      "Epoch 44/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1150 - accuracy: 0.9648 - val_loss: 0.0341 - val_accuracy: 0.9825\n",
      "Epoch 45/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1153 - accuracy: 0.9698 - val_loss: 0.0348 - val_accuracy: 0.9825\n",
      "Epoch 46/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1226 - accuracy: 0.9523 - val_loss: 0.0342 - val_accuracy: 0.9825\n",
      "Epoch 47/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1192 - accuracy: 0.9673 - val_loss: 0.0342 - val_accuracy: 0.9825\n",
      "Epoch 48/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1391 - accuracy: 0.9523 - val_loss: 0.0341 - val_accuracy: 0.9825\n",
      "Epoch 49/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1155 - accuracy: 0.9548 - val_loss: 0.0344 - val_accuracy: 0.9825\n",
      "Epoch 50/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1295 - accuracy: 0.9573 - val_loss: 0.0347 - val_accuracy: 0.9825\n",
      "Epoch 51/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1125 - accuracy: 0.9749 - val_loss: 0.0346 - val_accuracy: 0.9825\n",
      "Epoch 52/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0921 - accuracy: 0.9648 - val_loss: 0.0328 - val_accuracy: 0.9825\n",
      "Epoch 53/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1240 - accuracy: 0.9598 - val_loss: 0.0323 - val_accuracy: 0.9825\n",
      "Epoch 54/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1178 - accuracy: 0.9598 - val_loss: 0.0329 - val_accuracy: 0.9825\n",
      "Epoch 55/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1203 - accuracy: 0.9623 - val_loss: 0.0321 - val_accuracy: 0.9825\n",
      "Epoch 56/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0949 - accuracy: 0.9648 - val_loss: 0.0314 - val_accuracy: 0.9825\n",
      "Epoch 57/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1122 - accuracy: 0.9598 - val_loss: 0.0310 - val_accuracy: 0.9825\n",
      "Epoch 58/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0971 - accuracy: 0.9648 - val_loss: 0.0311 - val_accuracy: 0.9825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1011 - accuracy: 0.9598 - val_loss: 0.0310 - val_accuracy: 0.9825\n",
      "Epoch 60/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1089 - accuracy: 0.9774 - val_loss: 0.0320 - val_accuracy: 0.9825\n",
      "Epoch 61/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0942 - accuracy: 0.9724 - val_loss: 0.0318 - val_accuracy: 0.9825\n",
      "Epoch 62/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1053 - accuracy: 0.9698 - val_loss: 0.0313 - val_accuracy: 0.9825\n",
      "Epoch 63/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0835 - accuracy: 0.9648 - val_loss: 0.0310 - val_accuracy: 0.9825\n",
      "Epoch 64/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1022 - accuracy: 0.9799 - val_loss: 0.0316 - val_accuracy: 0.9825\n",
      "Epoch 65/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0967 - accuracy: 0.9774 - val_loss: 0.0313 - val_accuracy: 0.9825\n",
      "Epoch 66/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0830 - accuracy: 0.9749 - val_loss: 0.0311 - val_accuracy: 0.9825\n",
      "Epoch 67/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0930 - accuracy: 0.9698 - val_loss: 0.0308 - val_accuracy: 0.9825\n",
      "Epoch 68/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.9472 - val_loss: 0.0301 - val_accuracy: 0.9825\n",
      "Epoch 69/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1015 - accuracy: 0.9698 - val_loss: 0.0300 - val_accuracy: 0.9825\n",
      "Epoch 70/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0847 - accuracy: 0.9774 - val_loss: 0.0304 - val_accuracy: 0.9825\n",
      "Epoch 71/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0875 - accuracy: 0.9774 - val_loss: 0.0293 - val_accuracy: 0.9825\n",
      "Epoch 72/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1002 - accuracy: 0.9698 - val_loss: 0.0288 - val_accuracy: 0.9825\n",
      "Epoch 73/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0736 - accuracy: 0.9849 - val_loss: 0.0284 - val_accuracy: 0.9825\n",
      "Epoch 74/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0870 - accuracy: 0.9749 - val_loss: 0.0287 - val_accuracy: 0.9825\n",
      "Epoch 75/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.9749 - val_loss: 0.0279 - val_accuracy: 0.9825\n",
      "Epoch 76/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0987 - accuracy: 0.9724 - val_loss: 0.0275 - val_accuracy: 0.9825\n",
      "Epoch 77/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.9673 - val_loss: 0.0273 - val_accuracy: 0.9825\n",
      "Epoch 78/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.9698 - val_loss: 0.0271 - val_accuracy: 0.9825\n",
      "Epoch 79/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0781 - accuracy: 0.9673 - val_loss: 0.0274 - val_accuracy: 0.9825\n",
      "Epoch 80/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0770 - accuracy: 0.9824 - val_loss: 0.0276 - val_accuracy: 0.9825\n",
      "Epoch 81/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0827 - accuracy: 0.9774 - val_loss: 0.0274 - val_accuracy: 0.9825\n",
      "Epoch 82/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0772 - accuracy: 0.9799 - val_loss: 0.0276 - val_accuracy: 0.9825\n",
      "Epoch 83/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.9874 - val_loss: 0.0281 - val_accuracy: 0.9825\n",
      "Epoch 84/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 0.9749 - val_loss: 0.0279 - val_accuracy: 0.9825\n",
      "Epoch 85/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0847 - accuracy: 0.9799 - val_loss: 0.0288 - val_accuracy: 0.9825\n",
      "Epoch 86/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9824 - val_loss: 0.0287 - val_accuracy: 0.9825\n",
      "Epoch 87/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0798 - accuracy: 0.9774 - val_loss: 0.0293 - val_accuracy: 0.9825\n",
      "Epoch 88/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0851 - accuracy: 0.9623 - val_loss: 0.0276 - val_accuracy: 0.9825\n",
      "Epoch 89/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0927 - accuracy: 0.9774 - val_loss: 0.0276 - val_accuracy: 0.9825\n",
      "Epoch 90/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9849 - val_loss: 0.0272 - val_accuracy: 0.9825\n",
      "Epoch 91/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0751 - accuracy: 0.9874 - val_loss: 0.0277 - val_accuracy: 0.9825\n",
      "Epoch 92/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1054 - accuracy: 0.9774 - val_loss: 0.0272 - val_accuracy: 0.9825\n",
      "Epoch 93/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9749 - val_loss: 0.0275 - val_accuracy: 0.9825\n",
      "Epoch 94/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.9749 - val_loss: 0.0271 - val_accuracy: 0.9825\n",
      "Epoch 95/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.9799 - val_loss: 0.0265 - val_accuracy: 0.9825\n",
      "Epoch 96/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0887 - accuracy: 0.9824 - val_loss: 0.0264 - val_accuracy: 0.9825\n",
      "Epoch 97/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0806 - accuracy: 0.9849 - val_loss: 0.0259 - val_accuracy: 0.9825\n",
      "Epoch 98/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0891 - accuracy: 0.9799 - val_loss: 0.0263 - val_accuracy: 0.9825\n",
      "Epoch 99/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9774 - val_loss: 0.0269 - val_accuracy: 0.9825\n",
      "Epoch 100/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0770 - accuracy: 0.9774 - val_loss: 0.0262 - val_accuracy: 0.9825\n",
      "Epoch 101/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9824 - val_loss: 0.0258 - val_accuracy: 0.9825\n",
      "Epoch 102/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9824 - val_loss: 0.0261 - val_accuracy: 0.9825\n",
      "Epoch 103/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0832 - accuracy: 0.9824 - val_loss: 0.0263 - val_accuracy: 0.9825\n",
      "Epoch 104/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0766 - accuracy: 0.9774 - val_loss: 0.0266 - val_accuracy: 0.9825\n",
      "Epoch 105/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0736 - accuracy: 0.9799 - val_loss: 0.0262 - val_accuracy: 0.9825\n",
      "Epoch 106/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.9824 - val_loss: 0.0254 - val_accuracy: 0.9825\n",
      "Epoch 107/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0758 - accuracy: 0.9774 - val_loss: 0.0245 - val_accuracy: 0.9825\n",
      "Epoch 108/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0610 - accuracy: 0.9899 - val_loss: 0.0244 - val_accuracy: 0.9825\n",
      "Epoch 109/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0775 - accuracy: 0.9774 - val_loss: 0.0244 - val_accuracy: 0.9825\n",
      "Epoch 110/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.9874 - val_loss: 0.0249 - val_accuracy: 0.9825\n",
      "Epoch 111/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9698 - val_loss: 0.0255 - val_accuracy: 0.9825\n",
      "Epoch 112/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9849 - val_loss: 0.0262 - val_accuracy: 0.9825\n",
      "Epoch 113/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0759 - accuracy: 0.9849 - val_loss: 0.0257 - val_accuracy: 0.9825\n",
      "Epoch 114/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0721 - accuracy: 0.9724 - val_loss: 0.0256 - val_accuracy: 0.9825\n",
      "Epoch 115/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9774 - val_loss: 0.0242 - val_accuracy: 0.9825\n",
      "Epoch 116/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.9824 - val_loss: 0.0235 - val_accuracy: 0.9825\n",
      "Epoch 117/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0799 - accuracy: 0.9799 - val_loss: 0.0244 - val_accuracy: 0.9883\n",
      "Epoch 118/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9774 - val_loss: 0.0247 - val_accuracy: 0.9883\n",
      "Epoch 119/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.9749 - val_loss: 0.0256 - val_accuracy: 0.9825\n",
      "Epoch 120/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0749 - accuracy: 0.9724 - val_loss: 0.0243 - val_accuracy: 0.9825\n",
      "Epoch 121/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9749 - val_loss: 0.0235 - val_accuracy: 0.9825\n",
      "Epoch 122/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0828 - accuracy: 0.9724 - val_loss: 0.0240 - val_accuracy: 0.9825\n",
      "Epoch 123/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.9824 - val_loss: 0.0233 - val_accuracy: 0.9825\n",
      "Epoch 124/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0512 - accuracy: 0.9824 - val_loss: 0.0214 - val_accuracy: 0.9883\n",
      "Epoch 125/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0739 - accuracy: 0.9824 - val_loss: 0.0213 - val_accuracy: 0.9883\n",
      "Epoch 126/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0736 - accuracy: 0.9774 - val_loss: 0.0214 - val_accuracy: 0.9883\n",
      "Epoch 127/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0746 - accuracy: 0.9799 - val_loss: 0.0225 - val_accuracy: 0.9883\n",
      "Epoch 128/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9849 - val_loss: 0.0229 - val_accuracy: 0.9825\n",
      "Epoch 129/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 0.9799 - val_loss: 0.0224 - val_accuracy: 0.9883\n",
      "Epoch 130/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0739 - accuracy: 0.9774 - val_loss: 0.0224 - val_accuracy: 0.9825\n",
      "Epoch 131/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0806 - accuracy: 0.9824 - val_loss: 0.0231 - val_accuracy: 0.9825\n",
      "Epoch 132/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9874 - val_loss: 0.0247 - val_accuracy: 0.9883\n",
      "Epoch 133/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.9824 - val_loss: 0.0251 - val_accuracy: 0.9883\n",
      "Epoch 134/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9874 - val_loss: 0.0252 - val_accuracy: 0.9825\n",
      "Epoch 135/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.9824 - val_loss: 0.0263 - val_accuracy: 0.9825\n",
      "Epoch 136/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.9799 - val_loss: 0.0266 - val_accuracy: 0.9825\n",
      "Epoch 137/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 0.9874 - val_loss: 0.0262 - val_accuracy: 0.9825\n",
      "Epoch 138/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.9824 - val_loss: 0.0249 - val_accuracy: 0.9825\n",
      "Epoch 139/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9824 - val_loss: 0.0252 - val_accuracy: 0.9825\n",
      "Epoch 140/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.9774 - val_loss: 0.0254 - val_accuracy: 0.9825\n",
      "Epoch 141/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9824 - val_loss: 0.0257 - val_accuracy: 0.9825\n",
      "Epoch 142/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.9874 - val_loss: 0.0257 - val_accuracy: 0.9825\n",
      "Epoch 143/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.9849 - val_loss: 0.0256 - val_accuracy: 0.9825\n",
      "Epoch 144/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.9849 - val_loss: 0.0262 - val_accuracy: 0.9825\n",
      "Epoch 145/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.9824 - val_loss: 0.0249 - val_accuracy: 0.9883\n",
      "Epoch 146/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.9824 - val_loss: 0.0237 - val_accuracy: 0.9883\n",
      "Epoch 147/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9874 - val_loss: 0.0234 - val_accuracy: 0.9883\n",
      "Epoch 148/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 0.9824 - val_loss: 0.0228 - val_accuracy: 0.9883\n",
      "Epoch 149/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.9824 - val_loss: 0.0240 - val_accuracy: 0.9883\n",
      "Epoch 150/600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0760 - accuracy: 0.9849 - val_loss: 0.0252 - val_accuracy: 0.9883\n",
      "Epoch 00150: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17e27535488>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=600,\n",
    "          validation_data=(X_test, y_test), verbose=1,\n",
    "          callbacks=[early_stop]\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x17e2734db48>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 921us/step - loss: 0.0301 - accuracy: 0.9899\n",
      "Train score: [0.0301002636551857, 0.9899497628211975]\n",
      "6/6 [==============================] - 0s 836us/step - loss: 0.0252 - accuracy: 0.9883\n",
      "Test score: [0.02516816183924675, 0.988304078578949]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model - evaluate() returns loss and accuracy\n",
    "print(\"Train score:\", model.evaluate(X_train, y_train))\n",
    "print(\"Test score:\", model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1.\n",
      " 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Round to get the actual predictions\n",
    "# Note: has to be flattened since the targets are size (N,) while the predictions are size (N,1)\n",
    "predictions = np.round(predictions).flatten()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually calculated accuracy: 0.9883040935672515\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0252 - accuracy: 0.9883\n",
      "Evaluate output: [0.02516816183924675, 0.988304078578949]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy, compare it to evaluate() output\n",
    "print(\"Manually calculated accuracy:\", np.mean(predictions == y_test))\n",
    "print(\"Evaluate output:\", model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now save our model to a file\n",
    "model.save('breastcancer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
